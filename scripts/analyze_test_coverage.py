#!/usr/bin/env python3
"""
Purpose: Analyze test coverage overlap to identify duplicate and redundant tests
Scope: Queries coverage.py SQLite database to find tests covering identical code
Overview: This script analyzes the .coverage database generated by pytest-cov with
    dynamic context tracking to identify duplicate and redundant tests. It queries
    the SQLite database to find which tests cover which lines of code, calculates
    overlap percentages between all test pairs, and identifies tests that can be
    safely removed without impacting coverage. The analysis produces a report showing
    duplicate tests, subset relationships, and removal candidates.
Dependencies: sqlite3 (stdlib), coverage.numbits for SQLite functions
Exports: Main analysis function and reporting utilities
Interfaces: Command-line script that reads .coverage and outputs analysis reports
Implementation: Uses SQLite queries with coverage.py's custom numbits functions
"""

import sqlite3
import sys
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Set, Tuple

try:
    from coverage.numbits import register_sqlite_functions, numbits_to_nums
except ImportError:
    print("ERROR: coverage package not found. Install with: pip install coverage")
    sys.exit(1)


class CoverageAnalyzer:
    """Analyzes test coverage data to identify duplicate and redundant tests."""

    def __init__(self, coverage_db_path: str = ".coverage") -> None:
        """
        Initialize the coverage analyzer.

        Args:
            coverage_db_path: Path to the .coverage SQLite database
        """
        self.coverage_db_path = coverage_db_path
        self.conn: sqlite3.Connection | None = None
        self.test_coverage: Dict[str, Set[Tuple[str, int]]] = {}

    def connect(self) -> None:
        """Connect to the coverage database and register SQLite functions."""
        if not Path(self.coverage_db_path).exists():
            raise FileNotFoundError(
                f"Coverage database not found at {self.coverage_db_path}\n"
                "Run: pytest --cov=src --cov-report=html first"
            )

        self.conn = sqlite3.connect(self.coverage_db_path)
        register_sqlite_functions(self.conn)

    def close(self) -> None:
        """Close the database connection."""
        if self.conn:
            self.conn.close()

    def extract_test_coverage(self) -> None:
        """Extract coverage data for each test from the database."""
        if not self.conn:
            raise RuntimeError("Database not connected. Call connect() first.")

        cursor = self.conn.cursor()

        # Get all contexts (tests)
        cursor.execute("SELECT id, context FROM context WHERE context != ''")
        contexts = cursor.fetchall()

        print(f"Found {len(contexts)} test contexts")

        # For each test, get the lines it covers
        for context_id, context_name in contexts:
            # Skip non-test contexts (empty or setup/teardown markers)
            if not context_name or context_name == "":
                continue

            # Extract just the test name (remove |run, |setup, |teardown suffix)
            test_name = context_name.split("|")[0]

            # Get all lines covered by this test
            cursor.execute(
                """
                SELECT file.path, line_bits.numbits
                FROM line_bits
                JOIN file ON line_bits.file_id = file.id
                WHERE line_bits.context_id = ?
                """,
                (context_id,),
            )

            rows = cursor.fetchall()

            # Initialize test coverage if not exists
            if test_name not in self.test_coverage:
                self.test_coverage[test_name] = set()

            # Add all covered lines to this test's coverage set
            for file_path, numbits in rows:
                # Convert numbits to line numbers
                line_numbers = numbits_to_nums(numbits)
                for line_num in line_numbers:
                    self.test_coverage[test_name].add((file_path, line_num))

    def calculate_overlap(
        self, test1: str, test2: str
    ) -> Tuple[float, float, int, int, int]:
        """
        Calculate coverage overlap between two tests.

        Args:
            test1: Name of first test
            test2: Name of second test

        Returns:
            Tuple of (overlap_pct_1, overlap_pct_2, intersection, size1, size2)
            - overlap_pct_1: Percentage of test1 covered by test2
            - overlap_pct_2: Percentage of test2 covered by test1
            - intersection: Number of shared covered lines
            - size1: Total lines covered by test1
            - size2: Total lines covered by test2
        """
        coverage1 = self.test_coverage.get(test1, set())
        coverage2 = self.test_coverage.get(test2, set())

        if not coverage1 or not coverage2:
            return 0.0, 0.0, 0, len(coverage1), len(coverage2)

        intersection = coverage1 & coverage2
        intersection_size = len(intersection)

        overlap_pct_1 = (
            (intersection_size / len(coverage1) * 100) if len(coverage1) > 0 else 0.0
        )
        overlap_pct_2 = (
            (intersection_size / len(coverage2) * 100) if len(coverage2) > 0 else 0.0
        )

        return (
            overlap_pct_1,
            overlap_pct_2,
            intersection_size,
            len(coverage1),
            len(coverage2),
        )

    def find_duplicates(self, threshold: float = 95.0) -> List[Tuple[str, str, float]]:
        """
        Find test pairs with high coverage overlap.

        Args:
            threshold: Minimum overlap percentage to consider as duplicate (default 95%)

        Returns:
            List of (test1, test2, overlap_pct) tuples sorted by overlap percentage
        """
        duplicates = []

        test_names = list(self.test_coverage.keys())
        for i, test1 in enumerate(test_names):
            for test2 in test_names[i + 1 :]:
                overlap_pct_1, overlap_pct_2, _, _, _ = self.calculate_overlap(
                    test1, test2
                )

                # If either test is mostly covered by the other, consider it a duplicate
                max_overlap = max(overlap_pct_1, overlap_pct_2)
                if max_overlap >= threshold:
                    duplicates.append((test1, test2, max_overlap))

        # Sort by overlap percentage (highest first)
        duplicates.sort(key=lambda x: x[2], reverse=True)
        return duplicates

    def find_subsets(self) -> List[Tuple[str, str, float]]:
        """
        Find tests where one test's coverage is a complete subset of another.

        Returns:
            List of (subset_test, superset_test, percentage) tuples
        """
        subsets = []

        test_names = list(self.test_coverage.keys())
        for test1 in test_names:
            for test2 in test_names:
                if test1 == test2:
                    continue

                overlap_pct_1, _, _, _, _ = self.calculate_overlap(test1, test2)

                # If test1 is 100% covered by test2, test1 is a subset
                if overlap_pct_1 == 100.0:
                    subsets.append((test1, test2, overlap_pct_1))

        return subsets

    def get_removal_candidates(
        self, duplicate_threshold: float = 95.0
    ) -> List[Tuple[str, str, float]]:
        """
        Get prioritized list of tests that can be removed.

        Args:
            duplicate_threshold: Minimum overlap % to consider for removal

        Returns:
            List of (test_to_remove, test_to_keep, overlap_pct) sorted by priority
        """
        candidates = []

        # First, add complete subsets (100% overlap)
        subsets = self.find_subsets()
        for subset_test, superset_test, pct in subsets:
            candidates.append((subset_test, superset_test, pct))

        # Then add high-overlap duplicates
        duplicates = self.find_duplicates(duplicate_threshold)
        for test1, test2, overlap_pct in duplicates:
            # Prefer to keep the test with more coverage
            coverage1_size = len(self.test_coverage.get(test1, set()))
            coverage2_size = len(self.test_coverage.get(test2, set()))

            if coverage1_size < coverage2_size:
                candidates.append((test1, test2, overlap_pct))
            else:
                candidates.append((test2, test1, overlap_pct))

        # Sort by overlap percentage (highest first)
        candidates.sort(key=lambda x: x[2], reverse=True)

        # Deduplicate candidates (a test might appear multiple times)
        seen_tests_to_remove = set()
        unique_candidates = []
        for test_to_remove, test_to_keep, overlap_pct in candidates:
            if test_to_remove not in seen_tests_to_remove:
                unique_candidates.append((test_to_remove, test_to_keep, overlap_pct))
                seen_tests_to_remove.add(test_to_remove)

        return unique_candidates

    def export_candidates_json(
        self, candidates: List[Tuple[str, str, float]], output_file: str = ".artifacts/removal_candidates.json"
    ) -> None:
        """
        Export removal candidates to JSON file for use by removal script.

        Args:
            candidates: List of (test_to_remove, test_to_keep, overlap_pct) tuples
            output_file: Path to output JSON file
        """
        import json

        data = {
            "total_tests": len(self.test_coverage),
            "candidates": [
                {
                    "test_to_remove": test_to_remove,
                    "test_to_keep": test_to_keep,
                    "overlap_pct": overlap_pct,
                }
                for test_to_remove, test_to_keep, overlap_pct in candidates
            ],
        }

        with open(output_file, "w") as f:
            json.dump(data, f, indent=2)

        print(f"\nRemoval candidates exported to: {output_file}")

    def print_report(self, duplicate_threshold: float = 95.0, export_json: bool = True) -> None:
        """
        Print comprehensive analysis report.

        Args:
            duplicate_threshold: Minimum overlap % for duplicate detection
            export_json: Whether to export candidates to JSON file
        """
        print("\n" + "=" * 80)
        print("TEST COVERAGE ANALYSIS REPORT")
        print("=" * 80)

        print(f"\nTotal tests analyzed: {len(self.test_coverage)}")

        # Calculate total coverage
        all_covered_lines = set()
        for coverage_set in self.test_coverage.values():
            all_covered_lines.update(coverage_set)
        print(f"Total unique lines covered: {len(all_covered_lines)}")

        # Find subsets
        print("\n" + "-" * 80)
        print("COMPLETE SUBSETS (100% overlap)")
        print("-" * 80)
        subsets = self.find_subsets()
        if subsets:
            print(f"Found {len(subsets)} complete subset relationships:")
            for subset_test, superset_test, _ in subsets[:20]:  # Show first 20
                print(f"  ❌ {subset_test}")
                print(f"     └─> Completely covered by: {superset_test}")
        else:
            print("No complete subsets found.")

        # Find duplicates
        print("\n" + "-" * 80)
        print(f"HIGH OVERLAP DUPLICATES (≥{duplicate_threshold}%)")
        print("-" * 80)
        duplicates = self.find_duplicates(duplicate_threshold)
        if duplicates:
            print(f"Found {len(duplicates)} high-overlap test pairs:")
            for test1, test2, overlap_pct in duplicates[:20]:  # Show first 20
                print(f"  {overlap_pct:.1f}% overlap:")
                print(f"    - {test1}")
                print(f"    - {test2}")
        else:
            print(f"No duplicates found with ≥{duplicate_threshold}% overlap.")

        # Removal candidates
        print("\n" + "-" * 80)
        print("REMOVAL CANDIDATES (Prioritized)")
        print("-" * 80)
        candidates = self.get_removal_candidates(duplicate_threshold)
        if candidates:
            print(f"Found {len(candidates)} tests that could be removed:")
            print("\nTop 30 candidates:")
            for i, (test_to_remove, test_to_keep, overlap_pct) in enumerate(
                candidates[:30], 1
            ):
                print(f"\n{i}. [{overlap_pct:.1f}%] Remove: {test_to_remove}")
                print(f"         Keep: {test_to_keep}")

            # Calculate potential reduction
            total_tests = len(self.test_coverage)
            target_removal = int(total_tests * 0.4)  # 40% target
            actual_candidates = len(candidates)

            print("\n" + "-" * 80)
            print("REMOVAL SUMMARY")
            print("-" * 80)
            print(f"Total tests: {total_tests}")
            print(f"Target removal (40%): {target_removal}")
            print(f"Candidates found: {actual_candidates}")
            print(
                f"Coverage: {actual_candidates/target_removal*100:.1f}% of target"
                if target_removal > 0
                else "N/A"
            )
        else:
            print("No removal candidates found.")

        # Export to JSON
        if export_json and candidates:
            self.export_candidates_json(candidates)

        print("\n" + "=" * 80)


def main() -> None:
    """Main entry point for the script."""
    analyzer = CoverageAnalyzer()

    try:
        print("Connecting to coverage database...")
        analyzer.connect()

        print("Extracting test coverage data...")
        analyzer.extract_test_coverage()

        print("Analyzing coverage overlap...")
        analyzer.print_report(duplicate_threshold=95.0)

    except FileNotFoundError as e:
        print(f"ERROR: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"ERROR: Unexpected error: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
    finally:
        analyzer.close()


if __name__ == "__main__":
    main()
